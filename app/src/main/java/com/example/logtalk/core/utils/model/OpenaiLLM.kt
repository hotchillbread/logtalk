package com.example.logtalk.core.utils.model

import com.aallam.openai.api.chat.ChatCompletionRequest
import com.aallam.openai.api.chat.ChatMessage
import com.aallam.openai.api.chat.ChatRole
import com.aallam.openai.api.http.Timeout
import com.aallam.openai.api.model.ModelId
import com.aallam.openai.client.OpenAI
import com.example.logtalk.core.utils.Logger
import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.Job
import kotlinx.coroutines.flow.Flow
import kotlinx.coroutines.flow.collectLatest
import kotlinx.coroutines.launch
import kotlin.time.Duration.Companion.seconds

//ì¸í„°í˜ì´ìŠ¤
interface OpenaiLLM {
    suspend fun getResponse(prompt: String): String
}


//ê¸°ë³¸ ì³‡ë´‡
class OpenAILLMChatService(
    private val apiKey: String,
    private var systemPrompt: String,
    private val maxHistoryMessages: Int = 12 //ë””í´íŠ¸ ë²¨ë¥˜ ì„¤ì •
): OpenaiLLM {
    init { Logger.d("OpenAI Client Init - Received Key: $apiKey") }
    private val client = OpenAI(
        token = apiKey,
        timeout = Timeout(socket = 60.seconds)
    )

    private val chatHistory: MutableList<ChatMessage> = mutableListOf()
    //ê¸°ë¡ ì§¤ë¦´ê²½ìš° ìš”ì•½ ë‚´ìš©ìœ¼ë¡œ ëŒ€ì²´
    private var summaryMessage: ChatMessage? = null


    init {
        resetHistory()
    }

    fun resetHistory() {
        chatHistory.clear()
        chatHistory.add(
            ChatMessage(
                role = ChatRole.System,
                content = systemPrompt
            )
        )

        summaryMessage = null
    }

    // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ëŸ°íƒ€ì„ì— ì—…ë°ì´íŠ¸. ê¸°ë³¸ì€ íˆìŠ¤í† ë¦¬ ìœ ì§€ ëª¨ë“œ.
    fun updateSystemPrompt(newPrompt: String, preserveHistory: Boolean = true) {
        systemPrompt = newPrompt
        if (chatHistory.isEmpty()) {
            // ì•ˆì „ì¥ì¹˜: íˆìŠ¤í† ë¦¬ê°€ ë¹„ì–´ìˆìœ¼ë©´ ìƒˆ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¶”ê°€
            chatHistory.add(ChatMessage(ChatRole.System, systemPrompt))
            return
        }
        if (preserveHistory) {
            // ì²« ë©”ì‹œì§€ê°€ ì‹œìŠ¤í…œì´ë©´ ë‚´ìš©ì„ êµì²´í•˜ì—¬ UIì— ë…¸ì¶œ ì—†ì´ ì¦‰ì‹œ ë°˜ì˜
            val first = chatHistory.first()
            if (first.role == ChatRole.System) {
                chatHistory[0] = ChatMessage(ChatRole.System, systemPrompt)
            } else {
                // ì˜ˆìƒì¹˜ ëª»í•œ ìƒíƒœ: ì•ì— ì‚¬ìš©ì/ì–´ì‹œìŠ¤í„´íŠ¸ê°€ ìˆì„ ê²½ìš° ë§¨ ì•ì— ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‚½ì…
                chatHistory.add(0, ChatMessage(ChatRole.System, systemPrompt))
            }
            // ìš”ì•½ ë©”ì‹œì§€ëŠ” ìœ ì§€ë˜ë©° ë‹¤ìŒ ìš”ì²­ë¶€í„° ê·¸ëŒ€ë¡œ í™œìš©
        } else {
            // íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ëª¨ë“œ: ìƒˆ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ íˆìŠ¤í† ë¦¬ë¥¼ ì¬ì„¤ì •
            resetHistory()
        }
    }

    private suspend fun eliminateHistory() {
        if (chatHistory.size > maxHistoryMessages) {
            // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” í•­ìƒ ì²« ë²ˆì§¸ ë©”ì‹œì§€
            val systemPromptMessage = chatHistory.first()

            // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ê¸°ì¡´ ìš”ì•½ ë©”ì‹œì§€ë¥¼ ì œì™¸í•œ ì‹¤ì œ ëŒ€í™” ë‚´ì—­ë§Œ ì¶”ì¶œ
            val startIndex = if (summaryMessage != null) 2 else 1
            val messagesToSummarize = chatHistory.drop(startIndex)

            val summaryText = summaryMessages(messagesToSummarize)

            //ì´ì „ ëŒ€í™” ìš”ì•½ì„ ìœ„í•œ ë³€ìˆ˜ ê°’ í• ë‹¹ (ëˆ„ì  ìš”ì•½)
            summaryMessage = ChatMessage(
                role = ChatRole.System,
                content = "Previous conversation summary:\n${summaryMessage?.content ?: ""}\nRecent messages summary:\n$summaryText"
            )

            // íˆìŠ¤í† ë¦¬ ì¬êµ¬ì„±: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ìš”ì•½ ë©”ì‹œì§€ë§Œ ìœ ì§€
            chatHistory.clear()
            chatHistory.add(systemPromptMessage)
            summaryMessage?.let { chatHistory.add(it) }
        }
    }

    private suspend fun summaryMessages(messages: List<ChatMessage>): String {
        val summaryRequest = ChatCompletionRequest(
            model = ModelId("gpt-4o-mini"),
            messages = listOf(
                ChatMessage(ChatRole.System, "ë‹¤ìŒ ëŒ€í™”ë¥¼ ìƒì§€ ì•Šë„ë¡ ê°„ê²°í•˜ì§€ë§Œ ì¤‘ìš”í•œ ë‚´ìš©ì€ ë¹ ì§ì—†ì´ ìš”ì•½í•´."),
                *messages.toTypedArray()
            ),
            maxTokens = 200
        )

        val summaryResponse = client.chatCompletion(summaryRequest)
        return summaryResponse.choices.firstOrNull()?.message?.content ?: "ìš”ì•½ë‚´ìš© ì—†ìŒ"
    }

    override suspend fun getResponse(prompt: String): String {
        val userMessage = ChatMessage(
            role = ChatRole.User,
            content = prompt
        )
        chatHistory.add(userMessage)

        //íˆìŠ¤íŠ¸ë¡œ ì œê±°ì—¬ë¶€ ê²€ì‚¬
        eliminateHistory()


        val request = ChatCompletionRequest(
            model = ModelId("gpt-4o-mini"),
            // âœ¨ 3. ì €ì¥ëœ ì „ì²´ íˆìŠ¤í† ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ messagesë¡œ ì „ì†¡
            messages = chatHistory,
            maxTokens = 2000
        )

        val response = client.chatCompletion(request)

        val assistantContent = response.choices.firstOrNull()?.message?.content ?: ""

        // 4. ëª¨ë¸ ì‘ë‹µì„ ChatMessageë¡œ ë§Œë“¤ì–´ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ (ë‹¤ìŒ ìš”ì²­ì„ ìœ„í•´)
        if (assistantContent.isNotEmpty()) {
            val assistantMessage = ChatMessage(
                role = ChatRole.Assistant,
                content = assistantContent
            )
            chatHistory.add(assistantMessage)
        }

        return assistantContent
    }

    // ì„¤ì • í”„ë¡¬í”„íŠ¸ ë³€ê²½ì„ ì‹¤ì‹œê°„ ë°˜ì˜í•˜ê¸° ìœ„í•œ êµ¬ë… ê´€ë¦¬
    private var settingsScope: CoroutineScope? = null
    private var promptCollectJob: Job? = null

    // Settings ë“±ì—ì„œ ì œê³µí•˜ëŠ” Flow<String> (ìƒˆ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)ë¥¼ ë¶™ì—¬ ì‹¤ì‹œê°„ ë°˜ì˜
    fun attachSystemPromptFlow(promptFlow: Flow<String>, preserveHistory: Boolean = true) {
        // ê¸°ì¡´ êµ¬ë… í•´ì œ
        promptCollectJob?.cancel()
        if (settingsScope == null) settingsScope = CoroutineScope(Dispatchers.Default)
        promptCollectJob = settingsScope!!.launch {
            promptFlow.collectLatest { newPrompt ->
                updateSystemPrompt(newPrompt, preserveHistory)
            }
        }
    }

    // êµ¬ë… í•´ì œ (í•„ìš” ì‹œ í™”ë©´ íŒŒê´´ ë“±ì—ì„œ í˜¸ì¶œ)
    fun detachSystemPromptFlow() {
        promptCollectJob?.cancel()
        promptCollectJob = null
    }
}

class OpenIllegitimateSummarize(private val apiKey: String, private val firstMessage: String): OpenaiLLM {

    private val client = OpenAI(
        token = apiKey,
        timeout = Timeout(socket = 60.seconds)
    )
    private val titleMessage: MutableList<ChatMessage> = mutableListOf()
    init {
        // 1. ìš”ì•½ ì‘ì—…ì„ ì§€ì‹œí•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í˜¹ì€ ì‚¬ìš©ì ë©”ì‹œì§€)
        titleMessage.add(
            ChatMessage(
                role = ChatRole.System, // í˜¹ì€ ChatRole.User
                content = "ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ëŒ€í™” ì£¼ì œë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ ìš”ì•½ê°€ì…ë‹ˆë‹¤."
            )
        )

        titleMessage.add(
            ChatMessage(
                role = ChatRole.User,
                content = "ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ëŒ€í™” ì£¼ì œê°€ ë¬´ì—‡ì¸ì§€ ê°„ëµí•˜ê²Œ ìš”ì•½í•´ì¤˜:\n$firstMessage" // ğŸ‘ˆ
            )
        )
    }
    override suspend fun getResponse(prompt: String): String {
        val request = ChatCompletionRequest(
            model = ModelId("gpt-4o-mini"),
            // âœ¨ 3. ì €ì¥ëœ ì „ì²´ íˆìŠ¤í† ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ messagesë¡œ ì „ì†¡
            messages = titleMessage,
            maxTokens = 2000
        )

        val response = client.chatCompletion(request)

        return response.choices.firstOrNull()?.message?.content ?: ""
    }

}